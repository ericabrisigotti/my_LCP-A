{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\\. **PCA on 3D dataset**\n",
    "\n",
    "* Generate a dataset with 3 features each with N entries (N being ${\\cal O}(1000)$). With $N(\\mu,\\sigma)$ the normali distribution with mean $\\mu$ and $\\sigma$  standard deviation, generate the 3 variables $x_{1,2,3}$ such that:\n",
    "    * $x_1$ is distributed as $N(0,1)$\n",
    "    * $x_2$ is distributed as $x_1+N(0,3)$\n",
    "    * $x_3$ is given by $2x_1+x_2$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "N = 10**5\n",
    "data1 = np.random.normal(loc=0.,scale=1.,size=N)\n",
    "data2 = data1 + np.random.normal(loc=0.,scale=3.,size=N)\n",
    "data3 = 2*data1 + data2\n",
    "df = pd.DataFrame(data=np.array([data1,data2,data3]),index=['x1','x2','x3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the eigenvectors and eigenvalues of the covariance matrix of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.70301787e+01+0.j -5.48432680e-15+0.j  2.00819322e+00+0.j] [[-0.11516096 -0.81649658  0.56574843]\n",
      " [-0.57773653 -0.40824829 -0.70679123]\n",
      " [-0.80805845  0.40824829  0.42470563]]\n"
     ]
    }
   ],
   "source": [
    "from scipy import linalg as la\n",
    "co_mat=np.cov(df)\n",
    "e_val,e_vect=la.eig(co_mat)\n",
    "print(e_val,e_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find the eigenvectors and eigenvalues using SVD. Check that the two procedures yield to same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.30637869e-03 4.03288032e-05 3.28459651e-34] [[-0.11516096  0.56574843 -0.81649658]\n",
      " [-0.57773653 -0.70679123 -0.40824829]\n",
      " [-0.80805845  0.42470563  0.40824829]]\n"
     ]
    }
   ],
   "source": [
    "# I use SVD\n",
    "e_vect_svd, spectrum, Vt = np.linalg.svd(co_mat)\n",
    "# and estimate again that the eigenvalues and eigenvectors\n",
    "e_val_svd = spectrum**2/(N-1)\n",
    "# to check if the results from the two procedures are the same\n",
    "print(e_val_svd,e_vect_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# despite a switch in the column positions, the results are the visually the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we notice that one od the eigenvalues is extremely small: this is a sign that, through PCA, it will be possible to\n",
    "# reduce the dimensionality of the problem by, at least, one "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What percent of the total dataset's variability is explained by the principal components? Given how the dataset was constructed, do these make sense? Reduce the dimensionality of the system so that at least 99% of the total variability is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentuali:  [9.94475452e+01 5.52454811e-01 4.68378762e-30]\n"
     ]
    }
   ],
   "source": [
    "# to find how much of the dataset variability is explained by the principal components\n",
    "print('percentuali: ',e_val_svd/e_val_svd.sum()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35685963 -0.69092639  1.28779555 ...  0.86664872 -0.99047314\n",
      " -1.29982575]\n"
     ]
    }
   ],
   "source": [
    "# we see that\n",
    "# - most of the variability (over 99%) lies in x1\n",
    "# - a small amount (0.8%) of variability is due to x2\n",
    "# - an insignificant amount of variability is related to x3: as by definition, x3 is strictly correlated to the other variables\n",
    "#   x1 and x2 and can be easily dropped in the analysis\n",
    "# furthermore, the goal is to include at least 99% of the system, which is well describe through x1: also x2 can be dropped\n",
    "# we're left with just\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Redefine the data in the basis yielded by the PCA procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0             1             2             3             4      \\\n",
      "0  1.576866e+00 -6.086475e+00 -4.134244e+00  2.800460e-01  5.990158e+00   \n",
      "1 -5.635634e-16 -4.867738e-15  2.514698e-15  2.089218e-15  3.116993e-15   \n",
      "2 -3.097953e-01 -2.460194e+00  1.434723e+00  1.092518e+00  1.447434e+00   \n",
      "\n",
      "          5             6             7             8             9      ...  \\\n",
      "0 -1.078027e+00  4.374194e-01 -1.243904e+00 -2.093829e+00 -7.764924e-01  ...   \n",
      "1 -3.637312e-15 -2.001867e-16 -5.655395e-16  1.195792e-15 -6.743954e-15  ...   \n",
      "2 -1.883132e+00 -1.221996e-01 -2.801058e-01  6.274203e-01 -3.488683e+00  ...   \n",
      "\n",
      "          99990         99991         99992         99993         99994  \\\n",
      "0 -7.122696e-01  6.906407e+00  1.512762e+00  4.044138e+00 -5.659210e+00   \n",
      "1 -4.223381e-15 -1.251479e-15  4.004910e-15  1.806086e-15  1.013292e-15   \n",
      "2 -2.196384e+00 -7.460391e-01  2.125418e+00  9.231789e-01  6.237048e-01   \n",
      "\n",
      "          99995         99996         99997         99998         99999  \n",
      "0  4.224100e-01 -1.688108e+00 -2.443031e+00  2.670308e+00  4.595149e+00  \n",
      "1  4.030932e-15  7.067100e-17  1.924249e-15 -2.280503e-15 -2.394254e-15  \n",
      "2  2.087827e+00  5.390235e-02  1.034571e+00 -1.207176e+00 -1.362167e+00  \n",
      "\n",
      "[3 rows x 100000 columns]\n"
     ]
    }
   ],
   "source": [
    "# to get the data in the eigenvector basis\n",
    "e_df = pd.DataFrame(np.dot(e_vect.T,df))\n",
    "print(e_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the data points in the original and the new coordiantes as a set of scatter plots. Your final figure should have 2 rows of 3 plots each, where the columns show the (0,1), (0,2) and (1,2) proejctions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2\\. **PCA on a nD dataset**\n",
    "\n",
    "Start from the dataset you have genereted in the previous exercise and add uncorrelated random noise. Such noise should be represented by other 10 uncorrelated variables normal distributed, with standar deviation much smaller (say, a factor 50) than those used to generate the $x_1$ and $x_2$.\n",
    "\n",
    "Repeat the PCA procedure and compare the results with what you obtained before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.3 \\. **Looking at an oscillating spring** (60 MINUTES)\n",
    "\n",
    "Imagine you have $n$ cameras looking at a spring oscillating along the $x$ axis. Each  camera record the motion of the spring looking at it along a given direction defined by the pair $(\\theta_i, \\phi_i)$, the angles in spherical coordinates. \n",
    "\n",
    "Start from the simulation of the records (say ${\\cal O}(1000)$) of the spring's motion along the x axis, assuming a little random noise affects the measurements along the $y$. Rotate such dataset to emulate the records of each camera.\n",
    "\n",
    "Perform a Principal Component Analysis on the thus obtained dataset, aiming at finding the only one coordinate that really matters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.66710003e-14 1.00000000e+02 1.00079412e-15 1.38752551e-14\n",
      " 6.41470121e-15]\n"
     ]
    }
   ],
   "source": [
    "import scipy.linalg as la\n",
    "\n",
    "cameras = 5\n",
    "theta =  np.random.uniform(0,90,cameras)\n",
    "phi = np.random.uniform(0,180,cameras)\n",
    "time = 100\n",
    "r = np.random.uniform(0,1,time)\n",
    "meas = np.zeros((cameras,time))\n",
    "for i in range(cameras):\n",
    "    meas[i,:] = r*np.sin(phi[i])*np.cos(theta[i])\n",
    "val, vect = la.eig(np.cov(meas))\n",
    "print(np.abs(val)/la.norm(val)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4\\. **PCA on the MAGIC dataset** (optional)\n",
    "\n",
    "Perform a PCA on the magic04.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset and its description on the proper data directory\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.data -P ~/data/\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/magic/magic04.names -P ~/data/ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
